{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132f79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0cfa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/EKOLEMEN/nc1514/ml-tarflow/.venv/lib/python3.10/site-packages/IPython/core/completerlib.py:150: UserWarning: This is now an optional IPython functionality, setting rootmodules_cache requires you to install the `pickleshare` library.\n",
      "  ip.db['rootmodules_cache'] = rootmodules_cache\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformer_flow\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbcac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    channel_size: int = 3\n",
    "    img_size: int = 128\n",
    "    patch_size: int = 8\n",
    "    channels: int = 768\n",
    "    blocks: int = 8\n",
    "    layers_per_block: int = 8\n",
    "    nvp: bool = True\n",
    "    num_classes: int = 1000\n",
    "    resume: str = 'afhq_model_8_768_8_8_0.07.pth'\n",
    "    lr: float = 1e-4\n",
    "\n",
    "# Compatible class\n",
    "# args = Args(\n",
    "#     img_size=256,\n",
    "# )\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dcac697",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer_flow.Model(\n",
    "    in_channels=args.channel_size,\n",
    "    img_size=args.img_size,\n",
    "    patch_size=args.patch_size,\n",
    "    channels=args.channels,\n",
    "    num_blocks=args.blocks,\n",
    "    layers_per_block=args.layers_per_block,\n",
    "    nvp=args.nvp,\n",
    "    num_classes=args.num_classes,\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a1ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3635912/1230320305.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(args.resume, map_location='cuda')\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(args.resume, map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade732eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), betas=(0.9, 0.95), lr=args.lr, weight_decay=1e-4)\n",
    "lr_schedule = utils.CosineLRSchedule(optimizer, 1000, 3000, 1e-6, args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "541ff405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n",
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n",
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n",
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n",
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n",
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n",
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n",
      "Model: torch.Size([256, 768])\n",
      "Checkpoint: torch.Size([1024, 768])\n"
     ]
    }
   ],
   "source": [
    "for i in range(args.blocks):\n",
    "    print(f\"Model: {model.blocks[i].pos_embed.shape}\")\n",
    "    print(f\"Checkpoint: {ckpt[f'blocks.{i}.pos_embed'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19a3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_state_dict_custom(model, ckpt):\n",
    "    \n",
    "    # 1. Handle Sequence Length (Interpolation)\n",
    "    old_num_patches = ckpt['blocks.0.pos_embed'].shape[0]\n",
    "    new_num_patches = model.num_patches\n",
    "    old_grid = int(old_num_patches**0.5)\n",
    "    new_grid = int(new_num_patches**0.5)\n",
    "    \n",
    "    filtered_dict = {}\n",
    "    for k, v in ckpt.items():\n",
    "        # Interpolate Position Embeddings\n",
    "        if 'pos_embed' in k:\n",
    "            pos_tokens = v.unsqueeze(0).transpose(1, 2).reshape(1, -1, old_grid, old_grid)\n",
    "            interpolated = torch.nn.functional.interpolate(\n",
    "                pos_tokens, size=(new_grid, new_grid), mode='bicubic', align_corners=False\n",
    "            )\n",
    "            v = interpolated.reshape(1, -1, new_num_patches).transpose(1, 2).squeeze(0)\n",
    "            \n",
    "        # Interpolate Prior Variance (var)\n",
    "        elif k == 'var':\n",
    "            var_tokens = v.unsqueeze(0).transpose(1, 2).reshape(1, -1, old_grid, old_grid)\n",
    "            interpolated_var = torch.nn.functional.interpolate(\n",
    "                var_tokens, size=(new_grid, new_grid), mode='bicubic'\n",
    "            )\n",
    "            v = interpolated_var.reshape(1, -1, new_num_patches).transpose(1, 2).squeeze(0)\n",
    "\n",
    "        # Skip incompatible class embeddings and buffers\n",
    "        if 'class_embed' in k:\n",
    "            print(f\"Skipping {k}: AFHQ(3) -> ImageNet(1000)\")\n",
    "            continue\n",
    "        if 'attn_mask' in k:\n",
    "            continue # Use the mask already in your 128x128 model\n",
    "            \n",
    "        filtered_dict[k] = v\n",
    "\n",
    "    # 2. Load with strict=False to allow class_embed to stay initialized for ImageNet\n",
    "    msg = model.load_state_dict(filtered_dict, strict=False)\n",
    "    print(f\"Load Result: {msg}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9a019e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(args.resume, map_location='cpu', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2744b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping blocks.0.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Skipping blocks.1.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Skipping blocks.2.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Skipping blocks.3.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Skipping blocks.4.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Skipping blocks.5.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Skipping blocks.6.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Skipping blocks.7.class_embed: AFHQ(3) -> ImageNet(1000)\n",
      "Load Result: _IncompatibleKeys(missing_keys=['blocks.0.class_embed', 'blocks.0.attn_mask', 'blocks.1.class_embed', 'blocks.1.attn_mask', 'blocks.2.class_embed', 'blocks.2.attn_mask', 'blocks.3.class_embed', 'blocks.3.attn_mask', 'blocks.4.class_embed', 'blocks.4.attn_mask', 'blocks.5.class_embed', 'blocks.5.attn_mask', 'blocks.6.class_embed', 'blocks.6.attn_mask', 'blocks.7.class_embed', 'blocks.7.attn_mask'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "model_2 = _load_state_dict_custom(model, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cf5d539",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ckpt = torch.load(args.resume.replace('_model_', '_opt_'), map_location='cpu')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m lr_schedule\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'optimizer'"
     ]
    }
   ],
   "source": [
    "# ckpt = torch.load(args.resume.replace('_model_', '_opt_'), map_location='cpu')\n",
    "optimizer.load_state_dict(ckpt['optimizer'])\n",
    "lr_schedule.load_state_dict(ckpt['lr_schedule'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
